# Python + SQL ì—°ë™ ê°€ì´ë“œ (bigdataquery)

## ëª©ì°¨
- [[#bigdataquery ì†Œê°œ]]
- [[#ì—°ê²° ë° ê¸°ë³¸ ì‚¬ìš©]]
- [[#ì¿¼ë¦¬ ì‹¤í–‰]]
- [[#Pandas ì—°ë™]]
- [[#ë°ì´í„° ì²˜ë¦¬ íŒŒì´í”„ë¼ì¸]]
- [[#ì‹¤ì „ ì˜ˆì œ]]

---

## bigdataquery ì†Œê°œ

### bigdataqueryë€?

bigdataqueryëŠ” Impala SQLì„ Pythonì—ì„œ ì‚¬ìš©í•˜ê¸° ìœ„í•œ ì‚¬ë‚´ ëª¨ë“ˆì…ë‹ˆë‹¤.

**ì£¼ìš” ê¸°ëŠ¥:**
- Impala ë°ì´í„°ë² ì´ìŠ¤ ì—°ê²°
- SQL ì¿¼ë¦¬ ì‹¤í–‰
- Pandas DataFrame ë³€í™˜
- ëŒ€ìš©ëŸ‰ ë°ì´í„° ì²˜ë¦¬

### ì„¤ì¹˜ ë° import

```python
# bigdataquery import
from bigdataquery import BigDataQuery

# í•¨ê»˜ ì‚¬ìš©í•˜ëŠ” ë¼ì´ë¸ŒëŸ¬ë¦¬
import pandas as pd
import numpy as np
from datetime import datetime, timedelta
```

---

## ì—°ê²° ë° ê¸°ë³¸ ì‚¬ìš©

### ê¸°ë³¸ ì—°ê²°

```python
from bigdataquery import BigDataQuery

# BigDataQuery ê°ì²´ ìƒì„±
bdq = BigDataQuery()

# ì—°ê²° í™•ì¸
print("Impala ì—°ê²° ì„±ê³µ!")
```

### ê¸°ë³¸ ì¿¼ë¦¬ ì‹¤í–‰

```python
# ê°„ë‹¨í•œ ì¿¼ë¦¬
query = "SELECT * FROM wafer_data LIMIT 10"
result = bdq.execute(query)

print(result)
```

---

## ì¿¼ë¦¬ ì‹¤í–‰

### SELECT ì¿¼ë¦¬

```python
from bigdataquery import BigDataQuery

bdq = BigDataQuery()

# ê¸°ë³¸ SELECT
query = """
SELECT 
    wafer_id,
    lot_id,
    yield,
    process_date
FROM wafer_data
WHERE process_date >= '2025-10-01'
LIMIT 100
"""

result = bdq.execute(query)
print(result)
```

### íŒŒë¼ë¯¸í„°í™”ëœ ì¿¼ë¦¬

```python
# ë‚ ì§œ íŒŒë¼ë¯¸í„°
start_date = '2025-10-01'
end_date = '2025-10-15'

query = f"""
SELECT 
    COUNT(*) as total_wafers,
    AVG(yield) as avg_yield
FROM wafer_data
WHERE process_date BETWEEN '{start_date}' AND '{end_date}'
"""

result = bdq.execute(query)
print(f"ì „ì²´ ì›¨ì´í¼: {result}")
```

### ì§‘ê³„ ì¿¼ë¦¬

```python
# Lotë³„ í†µê³„
query = """
SELECT 
    lot_id,
    COUNT(*) as wafer_count,
    AVG(yield) as avg_yield,
    MIN(yield) as min_yield,
    MAX(yield) as max_yield
FROM wafer_data
WHERE process_date >= '2025-10-01'
GROUP BY lot_id
ORDER BY avg_yield DESC
"""

result = bdq.execute(query)
print(result)
```

---

## Pandas ì—°ë™

### DataFrameìœ¼ë¡œ ë³€í™˜

```python
from bigdataquery import BigDataQuery
import pandas as pd

bdq = BigDataQuery()

# ì¿¼ë¦¬ ì‹¤í–‰ ë° DataFrame ë³€í™˜
query = """
SELECT 
    wafer_id,
    lot_id,
    yield,
    defect_count,
    process_date
FROM wafer_data
WHERE process_date >= '2025-10-01'
"""

# DataFrameìœ¼ë¡œ ì§ì ‘ ë°›ê¸°
df = bdq.execute_to_df(query)

# ë˜ëŠ” execute í›„ ë³€í™˜
result = bdq.execute(query)
df = pd.DataFrame(result)

print(df.head())
print(f"\në°ì´í„° í¬ê¸°: {df.shape}")
```

### DataFrame ê¸°ë³¸ ë¶„ì„

```python
# ê¸°ë³¸ ì •ë³´
print("=== ë°ì´í„° ì •ë³´ ===")
print(df.info())

# í†µê³„ ìš”ì•½
print("\n=== í†µê³„ ìš”ì•½ ===")
print(df.describe())

# ê²°ì¸¡ì¹˜ í™•ì¸
print("\n=== ê²°ì¸¡ì¹˜ ===")
print(df.isnull().sum())
```

---

## ë°ì´í„° ì²˜ë¦¬ íŒŒì´í”„ë¼ì¸

### ETL íŒŒì´í”„ë¼ì¸

```python
from bigdataquery import BigDataQuery
import pandas as pd

def extract_data(start_date, end_date):
    """Extract: Impalaì—ì„œ ë°ì´í„° ì¶”ì¶œ"""
    bdq = BigDataQuery()
    
    query = f"""
    SELECT 
        wafer_id,
        lot_id,
        yield,
        defect_count,
        equipment_id,
        process_date
    FROM wafer_data
    WHERE process_date BETWEEN '{start_date}' AND '{end_date}'
    """
    
    df = bdq.execute_to_df(query)
    print(f"ì¶”ì¶œ ì™„ë£Œ: {len(df)}í–‰")
    return df

def transform_data(df):
    """Transform: ë°ì´í„° ë³€í™˜"""
    # ê²°ì¸¡ì¹˜ ì²˜ë¦¬
    df = df.fillna({'defect_count': 0})
    
    # ë“±ê¸‰ ê³„ì‚°
    df['grade'] = df['yield'].apply(
        lambda x: 'A' if x >= 98 else 'B' if x >= 95 else 'C'
    )
    
    # ë‚ ì§œ íƒ€ì… ë³€í™˜
    df['process_date'] = pd.to_datetime(df['process_date'])
    
    print(f"ë³€í™˜ ì™„ë£Œ: {len(df)}í–‰")
    return df

def load_data(df, output_file):
    """Load: ê²°ê³¼ ì €ì¥"""
    df.to_csv(output_file, index=False, encoding='utf-8-sig')
    print(f"ì €ì¥ ì™„ë£Œ: {output_file}")

# ETL ì‹¤í–‰
if __name__ == "__main__":
    # Extract
    df = extract_data('2025-10-01', '2025-10-15')
    
    # Transform
    df = transform_data(df)
    
    # Load
    load_data(df, 'processed_data.csv')
    
    print("\nETL ì™„ë£Œ!")
```

---

## ì‹¤ì „ ì˜ˆì œ

### ì˜ˆì œ 1: ì¼ì¼ ìˆ˜ìœ¨ ë³´ê³ ì„œ

```python
from bigdataquery import BigDataQuery
import pandas as pd
from datetime import datetime

def daily_yield_report(target_date):
    """ì¼ì¼ ìˆ˜ìœ¨ ë³´ê³ ì„œ ìƒì„±"""
    
    bdq = BigDataQuery()
    
    # ì¿¼ë¦¬
    query = f"""
    SELECT 
        lot_id,
        COUNT(*) as wafer_count,
        ROUND(AVG(yield), 2) as avg_yield,
        ROUND(STDDEV(yield), 2) as std_yield,
        ROUND(MIN(yield), 2) as min_yield,
        ROUND(MAX(yield), 2) as max_yield,
        SUM(CASE WHEN yield >= 95 THEN 1 ELSE 0 END) as pass_count
    FROM wafer_data
    WHERE process_date = '{target_date}'
    GROUP BY lot_id
    ORDER BY avg_yield DESC
    """
    
    df = bdq.execute_to_df(query)
    
    # Pass Rate ê³„ì‚°
    df['pass_rate'] = (df['pass_count'] / df['wafer_count'] * 100).round(2)
    
    # ê²°ê³¼ ì¶œë ¥
    print(f"\n=== {target_date} ìˆ˜ìœ¨ ë³´ê³ ì„œ ===\n")
    print(df.to_string(index=False))
    
    # CSV ì €ì¥
    output_file = f"yield_report_{target_date}.csv"
    df.to_csv(output_file, index=False, encoding='utf-8-sig')
    print(f"\në³´ê³ ì„œ ì €ì¥: {output_file}")
    
    return df

# ì‹¤í–‰
today = datetime.now().strftime('%Y-%m-%d')
report = daily_yield_report(today)
```

### ì˜ˆì œ 2: ì¥ë¹„ë³„ ì„±ëŠ¥ ë¶„ì„

```python
from bigdataquery import BigDataQuery
import pandas as pd

def equipment_performance(days=30):
    """ì¥ë¹„ë³„ ì„±ëŠ¥ ë¶„ì„"""
    
    bdq = BigDataQuery()
    
    query = f"""
    SELECT 
        e.equipment_name,
        e.equipment_type,
        COUNT(*) as processed_wafers,
        ROUND(AVG(w.yield), 2) as avg_yield,
        ROUND(STDDEV(w.yield), 2) as std_yield,
        COUNT(DISTINCT w.lot_id) as lots_handled,
        COUNT(DISTINCT DATE(w.process_date)) as active_days
    FROM wafer_data w
    INNER JOIN equipment_master e ON w.equipment_id = e.equipment_id
    WHERE w.process_date >= DATE_SUB(NOW(), INTERVAL {days} DAY)
    GROUP BY e.equipment_name, e.equipment_type
    HAVING processed_wafers >= 100
    ORDER BY avg_yield DESC
    """
    
    df = bdq.execute_to_df(query)
    
    # ì¼ì¼ í‰ê·  ì²˜ë¦¬ëŸ‰
    df['daily_throughput'] = (df['processed_wafers'] / df['active_days']).round(2)
    
    # ì„±ëŠ¥ ë“±ê¸‰
    df['performance'] = df['avg_yield'].apply(
        lambda x: 'Excellent' if x >= 98 else 'Good' if x >= 95 else 'Fair'
    )
    
    print("\n=== ì¥ë¹„ë³„ ì„±ëŠ¥ ë¶„ì„ ===\n")
    print(df.to_string(index=False))
    
    return df

# ì‹¤í–‰
equipment_stats = equipment_performance(days=30)
```

### ì˜ˆì œ 3: íŠ¸ë Œë“œ ë¶„ì„

```python
from bigdataquery import BigDataQuery
import pandas as pd
import matplotlib.pyplot as plt

def yield_trend_analysis(days=90):
    """ìˆ˜ìœ¨ íŠ¸ë Œë“œ ë¶„ì„"""
    
    bdq = BigDataQuery()
    
    # ì¼ë³„ ìˆ˜ìœ¨ ë°ì´í„°
    query = f"""
    SELECT 
        process_date,
        COUNT(*) as wafer_count,
        AVG(yield) as avg_yield,
        STDDEV(yield) as std_yield
    FROM wafer_data
    WHERE process_date >= DATE_SUB(NOW(), INTERVAL {days} DAY)
    GROUP BY process_date
    ORDER BY process_date
    """
    
    df = bdq.execute_to_df(query)
    df['process_date'] = pd.to_datetime(df['process_date'])
    
    # ì´ë™ í‰ê·  (7ì¼)
    df['ma_7'] = df['avg_yield'].rolling(window=7).mean()
    
    # ì‹œê°í™”
    plt.figure(figsize=(14, 6))
    
    plt.subplot(1, 2, 1)
    plt.plot(df['process_date'], df['avg_yield'], 
             alpha=0.5, label='Daily Yield')
    plt.plot(df['process_date'], df['ma_7'], 
             linewidth=2, label='7-day MA')
    plt.xlabel('Date')
    plt.ylabel('Yield (%)')
    plt.title('Yield Trend')
    plt.legend()
    plt.grid(True)
    plt.xticks(rotation=45)
    
    plt.subplot(1, 2, 2)
    plt.bar(df['process_date'], df['wafer_count'])
    plt.xlabel('Date')
    plt.ylabel('Wafer Count')
    plt.title('Daily Production')
    plt.xticks(rotation=45)
    
    plt.tight_layout()
    plt.savefig('yield_trend.png', dpi=300)
    print("íŠ¸ë Œë“œ ì°¨íŠ¸ ì €ì¥: yield_trend.png")
    plt.show()
    
    return df

# ì‹¤í–‰
trend_data = yield_trend_analysis(days=90)
```

### ì˜ˆì œ 4: ëŒ€ëŸ‰ ë°ì´í„° ì²˜ë¦¬

```python
from bigdataquery import BigDataQuery
import pandas as pd

def process_large_dataset(start_date, end_date, chunk_days=7):
    """ëŒ€ëŸ‰ ë°ì´í„°ë¥¼ ê¸°ê°„ë³„ë¡œ ë‚˜ëˆ ì„œ ì²˜ë¦¬"""
    
    bdq = BigDataQuery()
    
    # ë‚ ì§œ ë²”ìœ„ ìƒì„±
    date_range = pd.date_range(start=start_date, end=end_date, freq=f'{chunk_days}D')
    
    all_results = []
    
    for i in range(len(date_range) - 1):
        chunk_start = date_range[i].strftime('%Y-%m-%d')
        chunk_end = date_range[i+1].strftime('%Y-%m-%d')
        
        print(f"ì²˜ë¦¬ ì¤‘: {chunk_start} ~ {chunk_end}")
        
        query = f"""
        SELECT 
            lot_id,
            AVG(yield) as avg_yield,
            COUNT(*) as wafer_count
        FROM wafer_data
        WHERE process_date >= '{chunk_start}'
          AND process_date < '{chunk_end}'
        GROUP BY lot_id
        """
        
        df = bdq.execute_to_df(query)
        all_results.append(df)
    
    # ê²°í•©
    final_df = pd.concat(all_results, ignore_index=True)
    
    # Lotë³„ ì¬ì§‘ê³„
    summary = final_df.groupby('lot_id').agg({
        'wafer_count': 'sum',
        'avg_yield': 'mean'
    }).reset_index()
    
    print(f"\nì´ ì²˜ë¦¬ ì™„ë£Œ: {len(summary)} Lot")
    return summary

# ì‹¤í–‰
result = process_large_dataset('2025-01-01', '2025-10-15', chunk_days=7)
```

### ì˜ˆì œ 5: ì‹¤ì‹œê°„ ëª¨ë‹ˆí„°ë§

```python
from bigdataquery import BigDataQuery
import pandas as pd
import time
from datetime import datetime

def monitor_yield(threshold=95.0, interval=300):
    """ì‹¤ì‹œê°„ ìˆ˜ìœ¨ ëª¨ë‹ˆí„°ë§ (5ë¶„ ê°„ê²©)"""
    
    bdq = BigDataQuery()
    
    print("ìˆ˜ìœ¨ ëª¨ë‹ˆí„°ë§ ì‹œì‘...")
    print(f"ê²½ê³  ê¸°ì¤€: {threshold}%")
    print(f"í™•ì¸ ê°„ê²©: {interval}ì´ˆ\n")
    
    while True:
        try:
            # ìµœê·¼ 1ì‹œê°„ ë°ì´í„°
            query = """
            SELECT 
                COUNT(*) as count,
                AVG(yield) as avg_yield,
                MIN(yield) as min_yield
            FROM wafer_data
            WHERE process_time >= DATE_SUB(NOW(), INTERVAL 1 HOUR)
            """
            
            df = bdq.execute_to_df(query)
            
            if len(df) > 0 and df['count'][0] > 0:
                avg_yield = df['avg_yield'][0]
                min_yield = df['min_yield'][0]
                count = df['count'][0]
                
                timestamp = datetime.now().strftime('%Y-%m-%d %H:%M:%S')
                print(f"[{timestamp}] ì²˜ë¦¬: {count}ê°œ, í‰ê· : {avg_yield:.2f}%, ìµœì†Œ: {min_yield:.2f}%")
                
                # ê²½ê³  ì¡°ê±´
                if avg_yield < threshold:
                    print(f"  âš ï¸ ê²½ê³ : í‰ê·  ìˆ˜ìœ¨ì´ {threshold}% ë¯¸ë§Œì…ë‹ˆë‹¤!")
                    send_alert(f"ìˆ˜ìœ¨ ê²½ê³ : {avg_yield:.2f}%")
            
            time.sleep(interval)
            
        except KeyboardInterrupt:
            print("\nëª¨ë‹ˆí„°ë§ ì¢…ë£Œ")
            break
        except Exception as e:
            print(f"ì—ëŸ¬ ë°œìƒ: {e}")
            time.sleep(interval)

def send_alert(message):
    """ì•Œë¦¼ ì „ì†¡ (ì´ë©”ì¼, Slack ë“±)"""
    print(f"  ğŸ“§ ì•Œë¦¼: {message}")
    # ì‹¤ì œ ì•Œë¦¼ ë¡œì§ êµ¬í˜„

# ì‹¤í–‰ (Ctrl+Cë¡œ ì¢…ë£Œ)
# monitor_yield(threshold=95.0, interval=300)
```

### ì˜ˆì œ 6: ë°°ì¹˜ ë¦¬í¬íŠ¸ ìƒì„±

```python
from bigdataquery import BigDataQuery
import pandas as pd
from datetime import datetime, timedelta

def generate_weekly_report():
    """ì£¼ê°„ ì¢…í•© ë³´ê³ ì„œ ìƒì„±"""
    
    bdq = BigDataQuery()
    
    # ì§€ë‚œ ì£¼ ë‚ ì§œ
    today = datetime.now()
    last_week_end = today - timedelta(days=today.weekday() + 1)
    last_week_start = last_week_end - timedelta(days=6)
    
    start_date = last_week_start.strftime('%Y-%m-%d')
    end_date = last_week_end.strftime('%Y-%m-%d')
    
    print(f"=== ì£¼ê°„ ë³´ê³ ì„œ ({start_date} ~ {end_date}) ===\n")
    
    # 1. ì „ì²´ ìš”ì•½
    query1 = f"""
    SELECT 
        COUNT(DISTINCT lot_id) as total_lots,
        COUNT(*) as total_wafers,
        ROUND(AVG(yield), 2) as avg_yield,
        ROUND(STDDEV(yield), 2) as std_yield,
        SUM(CASE WHEN yield >= 95 THEN 1 ELSE 0 END) as pass_count
    FROM wafer_data
    WHERE process_date BETWEEN '{start_date}' AND '{end_date}'
    """
    
    summary = bdq.execute_to_df(query1)
    summary['pass_rate'] = (summary['pass_count'] / summary['total_wafers'] * 100).round(2)
    
    print("1. ì „ì²´ ìš”ì•½")
    print(summary.to_string(index=False))
    
    # 2. ì¼ë³„ íŠ¸ë Œë“œ
    query2 = f"""
    SELECT 
        process_date,
        COUNT(*) as wafer_count,
        ROUND(AVG(yield), 2) as avg_yield
    FROM wafer_data
    WHERE process_date BETWEEN '{start_date}' AND '{end_date}'
    GROUP BY process_date
    ORDER BY process_date
    """
    
    daily = bdq.execute_to_df(query2)
    
    print("\n2. ì¼ë³„ íŠ¸ë Œë“œ")
    print(daily.to_string(index=False))
    
    # 3. TOP/BOTTOM Lot
    query3 = f"""
    WITH lot_stats AS (
        SELECT 
            lot_id,
            COUNT(*) as wafer_count,
            AVG(yield) as avg_yield
        FROM wafer_data
        WHERE process_date BETWEEN '{start_date}' AND '{end_date}'
        GROUP BY lot_id
        HAVING wafer_count >= 10
    )
    SELECT * FROM (
        SELECT 'TOP' as category, lot_id, wafer_count, ROUND(avg_yield, 2) as avg_yield
        FROM lot_stats
        ORDER BY avg_yield DESC
        LIMIT 5
    )
    UNION ALL
    SELECT * FROM (
        SELECT 'BOTTOM' as category, lot_id, wafer_count, ROUND(avg_yield, 2) as avg_yield
        FROM lot_stats
        ORDER BY avg_yield ASC
        LIMIT 5
    )
    """
    
    top_bottom = bdq.execute_to_df(query3)
    
    print("\n3. TOP/BOTTOM Lot")
    print(top_bottom.to_string(index=False))
    
    # Excel ì €ì¥
    output_file = f"weekly_report_{start_date}_{end_date}.xlsx"
    with pd.ExcelWriter(output_file, engine='openpyxl') as writer:
        summary.to_excel(writer, sheet_name='Summary', index=False)
        daily.to_excel(writer, sheet_name='Daily', index=False)
        top_bottom.to_excel(writer, sheet_name='TopBottom', index=False)
    
    print(f"\në³´ê³ ì„œ ì €ì¥: {output_file}")

# ì‹¤í–‰
generate_weekly_report()
```

---

## ìœ ìš©í•œ íŒ

### ì¿¼ë¦¬ ìµœì í™”

```python
from bigdataquery import BigDataQuery

bdq = BigDataQuery()

# ì¢‹ìŒ: í•„ìš”í•œ ì»¬ëŸ¼ë§Œ ì„ íƒ
query_good = """
SELECT wafer_id, yield, lot_id
FROM wafer_data
WHERE process_date >= '2025-10-01'
"""

# ë‚˜ì¨: SELECT *
query_bad = """
SELECT *
FROM wafer_data
WHERE process_date >= '2025-10-01'
"""

# ì¢‹ìŒ: LIMIT ì‚¬ìš©
query_test = """
SELECT * FROM wafer_data
LIMIT 100
"""
```

### ì—ëŸ¬ ì²˜ë¦¬

```python
from bigdataquery import BigDataQuery
import pandas as pd

def safe_query(query):
    """ì—ëŸ¬ ì²˜ë¦¬ê°€ í¬í•¨ëœ ì¿¼ë¦¬ í•¨ìˆ˜"""
    try:
        bdq = BigDataQuery()
        df = bdq.execute_to_df(query)
        return df
    
    except Exception as e:
        print(f"ì¿¼ë¦¬ ì‹¤í–‰ ì—ëŸ¬: {e}")
        print(f"ì¿¼ë¦¬: {query}")
        return None

# ì‚¬ìš©
df = safe_query("SELECT * FROM wafer_data LIMIT 10")
if df is not None:
    print(df.head())
```

### ì—°ê²° ì¬ì‚¬ìš©

```python
from bigdataquery import BigDataQuery

# BigDataQuery ê°ì²´ë¥¼ í•œ ë²ˆë§Œ ìƒì„±
bdq = BigDataQuery()

# ì—¬ëŸ¬ ì¿¼ë¦¬ ì‹¤í–‰
df1 = bdq.execute_to_df("SELECT * FROM table1 LIMIT 10")
df2 = bdq.execute_to_df("SELECT * FROM table2 LIMIT 10")
df3 = bdq.execute_to_df("SELECT * FROM table3 LIMIT 10")
```

---

## ì„±ëŠ¥ ìµœì í™”

### íŒŒí‹°ì…˜ í™œìš©

```python
# ì¢‹ìŒ: íŒŒí‹°ì…˜ ì»¬ëŸ¼ í•„í„°
query = """
SELECT *
FROM wafer_data
WHERE year = 2025 AND month = 10
"""

# ë‚˜ì¨: í•¨ìˆ˜ ì‚¬ìš©
query = """
SELECT *
FROM wafer_data
WHERE YEAR(process_date) = 2025
"""
```

### ëŒ€ìš©ëŸ‰ ë°ì´í„° ì²˜ë¦¬

```python
from bigdataquery import BigDataQuery
import pandas as pd

def process_in_chunks(query, chunk_size=10000):
    """ì²­í¬ ë‹¨ìœ„ë¡œ ë°ì´í„° ì²˜ë¦¬"""
    bdq = BigDataQuery()
    
    # LIMITê³¼ OFFSET ì‚¬ìš©
    offset = 0
    all_data = []
    
    while True:
        chunk_query = f"{query} LIMIT {chunk_size} OFFSET {offset}"
        df = bdq.execute_to_df(chunk_query)
        
        if len(df) == 0:
            break
        
        # ì²­í¬ ì²˜ë¦¬
        processed = process_chunk(df)
        all_data.append(processed)
        
        offset += chunk_size
        print(f"ì²˜ë¦¬ ì™„ë£Œ: {offset}í–‰")
    
    return pd.concat(all_data, ignore_index=True)

def process_chunk(df):
    """ì²­í¬ ë°ì´í„° ì²˜ë¦¬"""
    # ì—¬ê¸°ì— ì²˜ë¦¬ ë¡œì§ êµ¬í˜„
    return df
```

---

## ê´€ë ¨ ë¬¸ì„œ

- [[Python ê¸°ì´ˆ ê°€ì´ë“œ]] - Python ê¸°ë³¸ ë¬¸ë²•
- [[Python ë°ì´í„° ë¶„ì„ ê°€ì´ë“œ]] - Pandas & NumPy
- [[Impala SQL ê°€ì´ë“œ]] - SQL ì¿¼ë¦¬ ì‘ì„±
- [[Impala SQL ì‹¤ì „ ì˜ˆì œ ëª¨ìŒ]] - SQL ì˜ˆì œ

---

**bigdataqueryë¡œ Impala ë°ì´í„°ë¥¼ íš¨ìœ¨ì ìœ¼ë¡œ í™œìš©í•˜ì„¸ìš”!** ğŸ”—
